## Taks 1

$N = 100 000 000$ — записей в таблице

$p = 1 000 000$ — страниц

$t_{random page} = 28$

$t_{sequential page} = 0.28$

$t_{tree}(k) = k \cdot t_{random page}$ (предполагается, что полученые номера страниц не сортируются/дедуплицируются)

$t_{direct}(k) = p \cdot t_{sequential page} = 1 000 000 \cdot 0.28 = 280 000 = t_{random page} \cdot 10 000 = t_{tree}(10 000)$

$t_{tree}(N) = 100 000 000 \cdot 28 = 2 800 000 000 = t_{direct}(N) \cdot 10 000$

<ins>Ответ:</ins> а) $t_{tree}(k) = k \cdot t_{random page}$; б) k < 10000; быстрее в 10000 раз.

## Taks 2

### Nested-loop join

В каждый момент в основной памяти хранится по 1 странице из обеих таблиц и одина страница для записи ответа.

`used_memory = 3 * sizeof(page)`

### Grace hash join

Для каждой партиции `R_i` строится хэш таблица в основной памяти функцией h'.

```
h' : typeof(R.α) → {1..m}
sizeof(hash_table) = sizeof(R_i) + (m + #R_i) * sizeof(void*)  // т. к. хэш таблица — массив из m односвязных списков суммарной длины #R_i
```

Одновременно с ней хранится одна страница из `S_i` и одна страница для результата.

`max_{time} used_memory → min_h` при равном размере партиций `∀i: R_i` ⇒ `#R_i = #R / n` ⇒ `sizeof(hash_table) = sizeof(R) / n + (m + #R / n) * sizeof(void*)`
`max_{time} used_memory → max_h` при одной полной партиции `∃i: R_i = R` и остальных пустых ⇒ `#R_i = #R` ⇒ `max_i sizeof(hash_table) = sizeof(R) + (m + #R / n) * sizeof(void*)`

`used_memory = sizeof(hash_table) + 2 * sizeof(page)`

### Sort merge join

#### Phase 1

Есть алгоритмы сортировки, не требующие доп. памяти. Нужна толька память для текущей страницы.

#### Phase 2

Для каждой отсортированой страницы нужно место длиной в одну запись в основной памяти (если мы мержим сразу всё). Открыто чтение потока байт из каждой страницы диска с произвольным изменяемым входным и выходным адресом. Не уверен, что диски такое позволяют, поэтому для имитации такого поведения может понадобиться ещё буфер чтения размером от одной страницы до размеров таблицы. (TODO ещё подумать над этим случаем)

Предположим, что в обеих таблицах ключ уникальный (иначе в худшем случае всё превратится в cross join, который реализуется через nested loop join).

`sizeof(merge_heap) = sizeof(record) * (sizeof(table) / sizeof(page))`

`used_memory = sizeof(R.merge_heap) + sizeof(S.merge_heap) + sizeof(read_buffer) = (sizeof(R.record) * sizeof(R) + sizeof(S.record) * sizeof(S)) / sizeof(page) + sizeof(read_buffer)`

При оптимизации по количеству основной памяти будет много этапов мержа, в каждом только из двух входных последовательностей. При этом таблицы будут сортироваться неконкурентно, а джоин будет проводится уже после того, как всё отсортировано. При мерже и при джойне в основной памяти нужно 2 входных страницы и одна выходная.

`used_memory = 3 * sizeof(page)`

### Table scan

1 страница для чтения, 1 страница для ответа.

`used_memory = 2 * sizeof(page)`
